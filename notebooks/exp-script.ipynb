{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Experiments\n",
    "## Online linear regression with absolute loss\n",
    "\n",
    "This notebook contains a experiment script for reproducing experimental results of the paper ``Parameter-free Online Linear Optimization with Side Information via Universal Coin Betting''.\n",
    "For each dataset `['BeijingPM2pt5', 'MetroInterstateTrafficVolume']`, run this notebook and run `generate-plots.ipynb`."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from timeit import default_timer as timer\n",
    "import numpy as np\n",
    "\n",
    "import datasets\n",
    "from learners import \\\n",
    "    MarkovSideInformation, \\\n",
    "    OnlineGradientDescent, \\\n",
    "    DimensionFreeExponentiatedGradient, AdaptiveNormal, \\\n",
    "    KT, ContextTreeWeighting, \\\n",
    "    Addition, Mixture\n",
    "from problems import LinearRegressionWithAbsoluteLoss\n",
    "from quantizer import Quantizer, get_standard_vector\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Pick one of ['BeijingPM2pt5', 'MetroInterstateTrafficVolume']\n",
    "dataset_name = 'BeijingPM2pt5'\n",
    "assert dataset_name in ['BeijingPM2pt5', 'MetroInterstateTrafficVolume']\n",
    "Dataset = getattr(datasets, dataset_name)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "problem = LinearRegressionWithAbsoluteLoss()\n",
    "\n",
    "dataset = Dataset(\n",
    "    root='../',\n",
    "    standardize=True,\n",
    "    rescale=False,\n",
    "    bias=True,\n",
    "    normalize=True,\n",
    "    batch_normalize=False)\n",
    "dim = dataset.X.shape[1]\n",
    "\n",
    "# data\n",
    "X, y = dataset.X, dataset.y\n",
    "data = X, y"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "X.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "depths_markov = [0] + list(range(1, 13, 2))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# OGD with Markov side information\n",
    "ogds = defaultdict(lambda: defaultdict(dict))\n",
    "lr_scales = np.array([1.5 ** n for n in np.arange(5, 25)])\n",
    "for i in range(dim):\n",
    "    for depth in depths_markov:\n",
    "        for lr_scale in lr_scales:\n",
    "            ogds[i][depth][lr_scale] = OnlineGradientDescent(\n",
    "                dim=dim,\n",
    "                lr_scale=lr_scale,\n",
    "                problem=problem,\n",
    "                side_information=MarkovSideInformation(\n",
    "                    depth=depth,\n",
    "                    quantizer=Quantizer(quantizer_vector=get_standard_vector(dim, i)),\n",
    "                ),\n",
    "            ).fit(data)\n",
    "        print(depth, end=' ')\n",
    "    print()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "init_wealth = 10 ** (-5.)\n",
    "\n",
    "# with Markov side information\n",
    "kt_markovs = defaultdict(dict)\n",
    "dfeg_markovs = defaultdict(dict)\n",
    "adanorm_markovs = defaultdict(dict)\n",
    "for i in range(dim):\n",
    "    for depth in depths_markov:\n",
    "        dfeg_markovs[i][depth] = DimensionFreeExponentiatedGradient(\n",
    "            dim=dim,\n",
    "            problem=problem,\n",
    "            side_information=MarkovSideInformation(\n",
    "                depth,\n",
    "                quantizer=Quantizer(quantizer_vector=get_standard_vector(dim, i)))\n",
    "        ).fit(data)\n",
    "\n",
    "        adanorm_markovs[i][depth] = AdaptiveNormal(\n",
    "            dim=dim,\n",
    "            problem=problem,\n",
    "            side_information=MarkovSideInformation(\n",
    "                depth,\n",
    "                quantizer=Quantizer(quantizer_vector=get_standard_vector(dim, i)))\n",
    "        ).fit(data)\n",
    "\n",
    "        kt_markovs[i][depth] = KT(\n",
    "            dim=dim,\n",
    "            init_wealth=init_wealth,\n",
    "            problem=problem,\n",
    "            side_information=MarkovSideInformation(\n",
    "                depth,\n",
    "                quantizer=Quantizer(quantizer_vector=get_standard_vector(dim, i)))\n",
    "        ).fit(data)\n",
    "        print(depth, end=' ')\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# with CTW\n",
    "times = []\n",
    "ctws = defaultdict(dict)\n",
    "max_depths_ctw = range(1, 13, 2)\n",
    "for i in range(dim):\n",
    "    print(\"quantizer {}\".format(i))\n",
    "    for max_depth in max_depths_ctw:\n",
    "        start = timer()\n",
    "        ctws[i][max_depth] = ContextTreeWeighting(\n",
    "            dim=dim,\n",
    "            init_wealth=init_wealth,\n",
    "            max_depth=max_depth,\n",
    "            problem=problem,\n",
    "            quantizer=Quantizer(quantizer_vector=get_standard_vector(dim, i)),\n",
    "        ).fit(data)\n",
    "        times.append(timer() - start)\n",
    "        print(max_depth, times[-1])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combine algorithms"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# combining Markovs over dimensions\n",
    "depths_combine_markovs_dims = range(1, 13, 2)\n",
    "add_markovs_over_dims = dict()\n",
    "mix_markovs_over_dims = dict()\n",
    "for depth in depths_combine_markovs_dims:\n",
    "    algorithms = [\n",
    "        KT(\n",
    "            dim=dim,\n",
    "            init_wealth=init_wealth,\n",
    "            problem=problem,\n",
    "            side_information=MarkovSideInformation(\n",
    "                depth,\n",
    "                quantizer=Quantizer(quantizer_vector=get_standard_vector(dim, i)))\n",
    "        )\n",
    "        for i in range(dim)]\n",
    "    add_markovs_over_dims[depth] = Addition(dim=dim, algorithms=algorithms).fit(data)\n",
    "    mix_markovs_over_dims[depth] = Mixture(dim, algorithms, init_wealth=init_wealth, weights=None).fit(data)\n",
    "    print(depth, end=' ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# combining Markovs over depths and dimensions\n",
    "max_depths_combine_markovs_depths_dims = range(1, 13, 2)\n",
    "add_markovs_over_depths_dims = dict()\n",
    "mix_markovs_over_depths_dims = dict()\n",
    "for depth in max_depths_combine_markovs_depths_dims:\n",
    "    algorithms = [\n",
    "        KT(\n",
    "            dim=dim,\n",
    "            init_wealth=init_wealth,\n",
    "            problem=problem,\n",
    "            side_information=MarkovSideInformation(\n",
    "                depth,\n",
    "                quantizer=Quantizer(quantizer_vector=get_standard_vector(dim, i)))\n",
    "        )\n",
    "        for d in range(depth) for i in range(dim)]\n",
    "    add_markovs_over_depths_dims[depth] = Addition(dim, algorithms).fit(data)\n",
    "    mix_markovs_over_depths_dims[depth] = Mixture(dim, algorithms, init_wealth=init_wealth, weights=None).fit(data)\n",
    "    print(depth, end=' ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# combining CTWs over dimensions\n",
    "max_depths_combine_ctws_dims = range(1, 13, 2)\n",
    "add_ctws_over_dims = dict()\n",
    "mix_ctws_over_dims = dict()\n",
    "\n",
    "for max_depth in max_depths_combine_ctws_dims:\n",
    "    algorithms = [\n",
    "        ContextTreeWeighting(\n",
    "            dim=dim,\n",
    "            init_wealth=init_wealth,\n",
    "            quantizer=Quantizer(get_standard_vector(dim, i)),\n",
    "            max_depth=max_depth,\n",
    "            problem=problem)\n",
    "        for i in range(dim)]\n",
    "    add_ctws_over_dims[max_depth] = Addition(dim, algorithms).fit(data)\n",
    "    mix_ctws_over_dims[max_depth] = Mixture(dim, algorithms, init_wealth=init_wealth, weights=None).fit(data)\n",
    "    print(max_depth, end=' ')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Save variables"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_name = dataset.name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "ogds_cum_loss = dict()\n",
    "for dim in ogds.keys():\n",
    "    ogds_cum_loss[dim] = dict()\n",
    "    for depth in ogds[dim].keys():\n",
    "        ogds_cum_loss[dim][depth] = dict()\n",
    "        for lr_scale in ogds[dim][depth].keys():\n",
    "            ogds_cum_loss[dim][depth][lr_scale] = ogds[dim][depth][lr_scale].cum_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "kt_markovs_cum_loss = dict()\n",
    "for dim in kt_markovs.keys():\n",
    "    kt_markovs_cum_loss[dim] = dict()\n",
    "    for depth in kt_markovs[dim].keys():\n",
    "        kt_markovs_cum_loss[dim][depth] = kt_markovs[dim][depth].cum_loss\n",
    "\n",
    "dfeg_markovs_cum_loss = dict()\n",
    "for dim in dfeg_markovs.keys():\n",
    "    dfeg_markovs_cum_loss[dim] = dict()\n",
    "    for depth in dfeg_markovs[dim].keys():\n",
    "        dfeg_markovs_cum_loss[dim][depth] = dfeg_markovs[dim][depth].cum_loss\n",
    "\n",
    "adanorm_markovs_cum_loss = dict()\n",
    "for dim in adanorm_markovs.keys():\n",
    "    adanorm_markovs_cum_loss[dim] = dict()\n",
    "    for depth in adanorm_markovs[dim].keys():\n",
    "        adanorm_markovs_cum_loss[dim][depth] = adanorm_markovs[dim][depth].cum_loss\n",
    "\n",
    "ctws_cum_loss = dict()\n",
    "for dim in ctws.keys():\n",
    "    ctws_cum_loss[dim] = dict()\n",
    "    for depth in ctws[dim].keys():\n",
    "        ctws_cum_loss[dim][depth] = ctws[dim][depth].cum_loss"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "add_markovs_over_dims_cum_loss = dict()\n",
    "for depth in add_markovs_over_dims.keys():\n",
    "    add_markovs_over_dims_cum_loss[depth] = add_markovs_over_dims[depth].cum_loss\n",
    "\n",
    "mix_markovs_over_dims_cum_loss = dict()\n",
    "for depth in mix_markovs_over_dims.keys():\n",
    "    mix_markovs_over_dims_cum_loss[depth] = mix_markovs_over_dims[depth].cum_loss\n",
    "\n",
    "add_markovs_over_depths_dims_cum_loss = dict()\n",
    "for depth in add_markovs_over_dims.keys():\n",
    "    add_markovs_over_depths_dims_cum_loss[depth] = add_markovs_over_depths_dims[depth].cum_loss\n",
    "\n",
    "mix_markovs_over_depths_dims_cum_loss = dict()\n",
    "for depth in mix_markovs_over_dims.keys():\n",
    "    mix_markovs_over_depths_dims_cum_loss[depth] = mix_markovs_over_depths_dims[depth].cum_loss\n",
    "\n",
    "add_ctws_over_dims_cum_loss = dict()\n",
    "for depth in add_ctws_over_dims.keys():\n",
    "    add_ctws_over_dims_cum_loss[depth] = add_ctws_over_dims[depth].cum_loss\n",
    "\n",
    "mix_ctws_over_dims_cum_loss = dict()\n",
    "for depth in mix_ctws_over_dims.keys():\n",
    "    mix_ctws_over_dims_cum_loss[depth] = mix_ctws_over_dims[depth].cum_loss\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import shelve\n",
    "\n",
    "filename = \"results/{}-cum-losses.out\".format(dataset.name)\n",
    "my_shelf = shelve.open(filename, 'n') # 'n' for new\n",
    "\n",
    "var_names = [\n",
    "    'dataset_name',\n",
    "    'dim',\n",
    "    'ogds_cum_loss',\n",
    "    'kt_markovs_cum_loss',\n",
    "    'dfeg_markovs_cum_loss',\n",
    "    'adanorm_markovs_cum_loss',\n",
    "    'ctws_cum_loss',\n",
    "    'add_markovs_over_dims_cum_loss',\n",
    "    'mix_markovs_over_dims_cum_loss',\n",
    "    'add_markovs_over_depths_dims_cum_loss',\n",
    "    'mix_markovs_over_depths_dims_cum_loss',\n",
    "    'add_ctws_over_dims_cum_loss',\n",
    "    'mix_ctws_over_dims_cum_loss',\n",
    "]\n",
    "\n",
    "for key in var_names:\n",
    "    try:\n",
    "        my_shelf[key] = globals()[key]\n",
    "    except TypeError:\n",
    "        #\n",
    "        # __builtins__, my_shelf, and imported modules can not be shelved.\n",
    "        #\n",
    "        print('ERROR shelving: {0}'.format(key))\n",
    "my_shelf.close()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}